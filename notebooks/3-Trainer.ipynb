{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2200578-981c-4261-9a0e-4fe3c6d61596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/Text-Summarizer/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5c0b7a-f2df-4ba4-b3f6-7a24038ceca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/Text-Summarizer\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218bf37c-8eaf-4ce8-b085-e340da763ba0",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70e8df3e-e93b-4576-85e0-937286b248fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b61bb788-fa20-4bd2-bdc4-4d7ae9ad7d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainerConfig:\n",
    "    config_path: str\n",
    "    config_model_name: str\n",
    "    config_tokenizer_name: str\n",
    "    config_tokenized_data_path: str\n",
    "    params_epochs: int\n",
    "    params_warmup_steps: int\n",
    "    params_batch_size: int\n",
    "    params_weight_decay: float\n",
    "    params_logging_steps: int\n",
    "    params_evaluation_strategy: str\n",
    "    params_eval_steps: int\n",
    "    params_save_steps: int\n",
    "    params_gradient_accumulation_steps: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5073b-e565-42d9-be7d-7ced3e671e9f",
   "metadata": {},
   "source": [
    "# Configuration Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f65bb6d-58f7-481c-ac85-b4bb35ca84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import ConfigManager\n",
    "from src.utils import create_dirs\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3643804e-dec6-4b0b-9df7-ea50c2daac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigManager(ConfigManager):\n",
    "    def get_trainer_config(self):\n",
    "        config = self.config.fine_tuning\n",
    "        tokenization_config = self.config.tokenization\n",
    "        params = self.params.TrainingArgs\n",
    "\n",
    "        direct = join(self.artifacts, config.folder)\n",
    "\n",
    "        create_dirs([direct])\n",
    "\n",
    "        return TrainerConfig(\n",
    "            config_path=direct,\n",
    "            config_model_name=config.model_name,\n",
    "            config_tokenizer_name=tokenization_config.model_name,\n",
    "            config_tokenized_data_path=join(self.artifacts, tokenization_config.folder),\n",
    "            params_epochs=params.epochs,\n",
    "            params_warmup_steps=params.warmup_steps,\n",
    "            params_batch_size=params.batch_size,\n",
    "            params_weight_decay=params.weight_decay,\n",
    "            params_logging_steps=params.logging_steps,\n",
    "            params_evaluation_strategy=params.evaluation_strategy,\n",
    "            params_eval_steps=params.eval_steps,\n",
    "            params_save_steps=params.save_steps,\n",
    "            params_gradient_accumulation_steps=params.gradient_accumulation_steps\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc9f3d1-08bf-4171-9a76-1dc647967cd5",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc58bdf4-d2aa-4dc6-9954-4d24ce918204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-08 19:39:59,089: INFO: config: PyTorch version 2.3.1.post300 available.]\n",
      "[2024-10-08 19:39:59,091: INFO: config: TensorFlow version 2.17.0 available.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 19:40:03.392873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-08 19:40:03.405784: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-08 19:40:03.409873: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-08 19:40:03.420348: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "185bd215-1956-49db-a641-0bdd99d223fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, config: TrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def fit(self):\n",
    "        tokenized_data = load_from_disk(self.config.config_tokenized_data_path)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.config_tokenizer_name)\n",
    "\n",
    "        device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(self.config.config_model_name).to(device)\n",
    "        \n",
    "        data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "        \n",
    "        args = TrainingArguments(\n",
    "            output_dir=self.config.config_path,\n",
    "            num_train_epochs=self.config.params_epochs,\n",
    "            warmup_steps=self.config.params_warmup_steps,\n",
    "            per_device_train_batch_size=self.config.params_batch_size,\n",
    "            per_device_eval_batch_size=self.config.params_batch_size,\n",
    "            weight_decay=self.config.params_weight_decay,\n",
    "            logging_steps=self.config.params_logging_steps,\n",
    "            evaluation_strategy=self.config.params_evaluation_strategy,\n",
    "            eval_steps=self.config.params_eval_steps,\n",
    "            save_steps=int(self.config.params_save_steps),\n",
    "            gradient_accumulation_steps=self.config.params_gradient_accumulation_steps\n",
    "        )\n",
    "\n",
    "\n",
    "        model = Trainer(\n",
    "            model=model, args=args,\n",
    "            tokenizer=tokenizer, data_collator=data_collator,\n",
    "            train_dataset=tokenized_data[\"train\"], \n",
    "            eval_dataset=tokenized_data[\"validation\"]\n",
    "        )\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        model.save_model(join(self.config.config_path, 'model'))\n",
    "        tokenizer.save_pretrained(join(self.config.config_path, 'tokenizer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e21f33d-787c-4735-8cb6-d88066adce6d",
   "metadata": {},
   "source": [
    "# Run the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fe71979-b7a9-4e00-b8ae-1bdeb78342fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-08 19:40:17,383: INFO: utils: The file: params.yaml loaded successfully...]\n",
      "[2024-10-08 19:40:17,385: INFO: utils: The file: config.yaml loaded successfully...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='920' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [920/920 31:10, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.896500</td>\n",
       "      <td>1.677440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.739500</td>\n",
       "      <td>1.536679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.670100</td>\n",
       "      <td>1.456872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.647200</td>\n",
       "      <td>1.430026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigManager().get_trainer_config()\n",
    "    Model(config=config).fit()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
